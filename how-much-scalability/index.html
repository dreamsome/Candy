

<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <base target="_top">

    <title>你有多少扩展性，又需要多少？</title>
    <link rel="stylesheet" href="style.css" type="text/css">

</head>

<body>

<div class="header">
<h1>你有多少扩展性，又需要多少？</h1>

<div class="meta"><a href="http://www.drdobbs.com/parallel/201202924">Original Link</a> / May 2012 /<a href="http://chengyichao.info/">onesuper</a> 译</p></div>
</div>

<div class="content">


<p>在你的程序中，有多少独立的任务可以在任意时刻运行？换一种问法，你的代码能够利多少个核（或硬件线程，或节点）来加速？从什么时候起这个问题的答案不再是“有多少个核就能用多少”？</p>

<p>表 1 总结了三种级别的吞吐量，他们可能出现在任何程序或操作中，我们使用大 O 表示法来描述在任意时刻可以被执行的 CPU 密集型任务的数量。这篇文章的其余部分会描述这三种级别的可扩展性，并总结它们分别适用于哪种场合。</p>

<p>上个月 <a href="#scalability-note-3">[2]</a>，我们讨论了并发的三根“柱子”：“柱子 1” 通过异步构造工作的方式来独立任务，使用消息通信机制；“柱子 2” 在算法和数据结构的上开发并行性来得到可伸缩的吞吐量；“柱子3” 使用共享变量。这个月我们的主题是面向吞吐量的技术，它们用到了“柱子 1” 和“柱子 2”。</p>

<table>

<thead>
<tr>
<th>级别</th> <th>O(1): 单核</th> <th>O(K)：固定核数</th> <th>O(N)：可扩展的</th>
</tr>
</thread>

<tbody>

<tr>
<td><strong>标语</strong></td>
<td>每次做一件事情</td>
<td>显式地分配线程数</td>
<td>免费的午餐回来了！ <a href="#scalability-note-3">[3]</a></td>
</tr>

<tr>
<td><strong>概述</strong></td>
<td>串行程序和有瓶颈的并行程序</td>
<td>显式地表达有多少工作可以并行地完成</td>     
<td>把所有隐藏的并发性都表达出来，而且要能有效地映射到 N 个核</td>
</tr>


<tr>
<td><strong>举例</strong></td>
<td>使用了全局锁、消息队列的多线程代码，偶尔或断断续续的后台工作</td>
<td>流水线，任务分工被硬编码，规则或持续的后台计算</td>
<td>树遍历，快速排序，编译</td>
</tr>


<tr>

<td><strong>应用性</strong></td>
<td>单核硬件，单线程操作系统，非 CPU 受限的程序 <a href="#scalability-note-5">[5]</a></td>
<td>硬件的并发性固定，程序中 CPU 受限的部分的伸缩性很有限</td>
<td>硬件的并发性可变，程序中 CPU 受限的部分可以很有效地并行</td>
</tr>

<tr>
<td><strong>举例</strong></td>
<td>针对古老硬件、小型嵌入式系统、单核游戏机编写的代码；简单的字处理器</td>
<td>针对一代多核游戏机编写的游戏程序；代码的关键操作是有顺序先后的（可以被流水化，但不能完全并行）</td>
<td>针对消费级硬件和未来可升级的游戏机编写的主流桌面/服务器软件，它们有很明显的 CPU 受限特性</td>

</tr>

<tr>
<td><strong>柱子 <a href="#scalability-note-2">[2]</a> 和今天的主流工具</strong></td>
<td colspan="2">柱子 1：线程，消息传递，期货 <a href="#scalability-note-6">[6]</a></td>
<td>支柱 2： 线程池，期货，OpenMP</td>
</tbody>

</table>

<p><strong>表一</strong></p>

<h3>O(1): 串行代码</h3>

<p>O(1) 意味着程序通常只有一个可以在任意时刻被执行的 CPU 密集型的任务。它有时可能也会做一些并发的操作，例如辅助前台主要工作进行的一些后台任务，但是这些额外的工作量不足以有效地利用第二个核。</p>

<p>这一类不仅仅包括了所有的串行代码，还包括线程是串行地被执行的并发程序，例如用了全局锁或消息队列以后，它们的吞吐量和串行程序几乎一样。这两种 <em>O(1)</em> 的代码已经把免费的午餐吃完了，不过相比之下，完全的串行代码响应性更差，而并发程序利于处理一些后台的异步工作。<a href="#scalability-note-1">[1, 2]</a></p>

<p>比如当我在 Microsoft Word 中敲下了这个段落时，WINWORD.EXE 运行了 8 到 11 个活动线程，但是几乎所有的 CPU 核都是空闲的。Word 每过一段时间在后台进行保存时，某个核的利用率上升到 50% 以上，大概持续 2 秒钟，然后系统再次进入空闲状态。这种情况下 Word 就是 <em>O(1)</em> 的，即使程序内部使用了多个线程，但把它放到一个有更多核的系统上运行，性能也不太可能得到改善。</p>

<p>在所有 <em>O(1)</em> 的情况中，如果我们想让 CPU 受限操作产生更大的吞吐量，唯一的办法就是用传统方法优化我们的代码，增加计算核心是徒劳的。</p>

<h3>O(K)：显示分配线程的代码</h3>

<p><em>O(k)</em> 意味着任意时刻系统中有固定数量的工作可以交给固定数目的核去完成。而这些数量是硬编码在程序中的，同样无法在执行的过程中根据硬件的并发性做出调整。</p>

<p>例如在第一人称的动作游戏中，为了利用更多的核，把游戏中 CPU 受限的工作一分为三，交给三个线程去做：线程 1 负责处理游戏的物理效果，线程 2 负责渲染画面，线程 3 负责模拟非玩家角色 AI。为了简化问题，我们假设这三个线程的工作量一样，并且相互之间存在依赖关系。现在游戏在一台单核机器上可以正常运行，操作系统在一个核上交替执行这三个线程。当用户把机器升级成双核后，游戏运行得更快了，但并不是 2 倍，因为当我们把线程 1 调度到第一个核上，线程 2 调度到核第二个上，而线程 3 也必须调度到其中一个核上。如果我们把线程 3 和线程 1 一起调度到第一个核上，那么线程 2 会因为依赖于 1 和 3 的计算结果，所以有一半的时间是空闲的。如果我们把线程 3 调度到这两个核上，不但会引起 cache 抖动，而且把线程 3 从一个核移动到另一个核上也会带来一定开销。所以程序虽然比原来更快了，但不是两倍。当用户升级成四核的机器时，游戏又比原来快了，但是只比单核时快了 3 倍，或 3 倍多一点点，因为一些后台程序可以放到第四个核上去运行。而当用户升级到八核机器时，什么也没有发生。然后是十六核，更加什么也没发生了。<em>O(3)</em> 的程序就适合在 3 个核上运行，这是在程序里写死的，与输入和执行环境无关。</p>

<p>于此密切相关的一种技术是流水线，当我们有一个集合的数据需要处理时，它就可以派上用场了。因为这些数据之间存在次序上的依赖关系，所以我们不能用 <em>O(N)</em> 的技术对它们进行并行化。考虑在一个通信子系统中，数据包是通过网络进行发送，子系统的输入是未经处理的数据包流，在发送一个指定的包前，先要对包加上头部信息，然后压缩，最后进行加密。这三个步骤必须按照这个顺序进行，因此不能并行。一种方法是用三个 agent，agent 之间通过消息队列进行通信：第一个 agent（通常是一个线程）负责给包上头部信息，然后发送给第二个 agent；第二个 agent 收到包以后进行压缩，发送给第三个 agent，后者对包进行加密处理，最后发送给网络。和之前提到的那个游戏一样，这个子系统有 <em>O(3)</em> 的并行性，前提是流水线的每个阶段计算量相同。这里我们用了“柱子 1”（独立的 agent 和消息传递机制；详见 <a href="#scalability-note-2">[2]</a>）,它可以很自然地表示成流水线：流水线中的每个步骤相对独立，通过消息传递来在不同阶段之间进行同步。</p>

<p>最后我们回到 Word，不过这次变成了“听写”。当我打开语音识别功能让 Word 听写一个段落时，两个核变得一样忙，但系统中其余的核仍旧是空闲的。使用“听写”模式的 Word 是一个 <em>O(2)</em> 的程序，它在一个单核系统上可以正常运行，在双核系统上运行得更快，但更多的核并不会提升程序的运行速度和“听写”的正确率。</p>

<p>在给定工作负载的情况下，一个 <em>O(K)</em> 的程序被显示地编写成更适合在 K 个核上运行。当环境中的核数大于 K 时，<em>O(K)</em> 程序的代码无法利用多余的核。而环境中的核数少于 K 时，程序会因为负载不平衡产生巨大性能损失，导致一部分核不能被完全利用。</p>

<h3>O(1) 和 O(K) 的比较</h3>

<p>警惕的读者可能已经发现在其它计算机科学的语境中通常不区分 <em>O(1)</em> 和 <em>O(K)</em> 这两种复杂度，因为大 O 表示法忽略常数因子，毕竟 K=1 只是特殊情况。没错，这里也是，同和 <em>O(N)</em> 相比，<em>O(K)</em> 和 <em>O(1)</em> 非常接近。它们都把并发以某种显示的结构硬编码在了代码中，因此它们不能扩展到任意数量的核上。尽管如此，还是需要指出这两者的一些区别。</p>

<p><em>O(1)</em> 是一种重要的特殊情况，因为它针对以下三种重要的场景：</p>

<ul>
<li>单核硬件，包括一些古老的硬件系统和一些游戏机，例如任天堂 Wii。</li>
<li>不支持并发的操作系统，例如在一些操作系统中没有线程的概念。</li>
<li>一些非 CPU 受限的程序，无论怎么分它们都消耗不了一个核的计算能力，例如一个简单的字处理器。</li>
</ul>

<p>如果你没有理由和能力摆脱以上三种限制，可能没有很大必要费九牛二虎之力把代码改成 <em>O(K)</em> 或 <em>O(N)</em> 的，因为额外的并发性在以上这些系统中永远体现不出来。但是别忘了，即使在 <em>O(1)</em> 的世界中，并发仍旧是让程序获得更好响应的最好方法，即使在一个不支持线程这样令人蛋疼操作系统中，一些像事件驱动编程这样的技术也会奏效。而 <em>O(K)</em> 更适合那些并发性固定的场景：</p>

<ul>
<li>硬件固定，比如某一代的多核游戏机。举个例子，当我们为 XBox 360 开发一款游戏时，最好写一个 <em>O(6)</em> 的程序，因为这代的游戏机都有 6 个硬件线程（3个核，每个核有两个硬件线程）；同样的，PS3 需要 <em>O(8)</em> 或 <em>O(9)</em> 的程序，因为它有 1+8 个核（一个通用核，8个专用核）。这些配置在游戏机换代之前不会改变。</li>
<li>关键操作不能被完全并行化的程序：在刚刚那个包发送的例子中，CPU 密集型操作之间具有次序上的依赖关系。程序的每个部分不是独立的，因此不能放开了并行执行。而流水线是一种在串行操作中提取并行性的经典方法。K 个阶段、每个阶段耗时相等的流水线最多可以达到 <em>O(K)</em>。虽然 <em>O(K)</em> 不是可扩展的，但是有战术地是使用还是可以继续享用免费的午餐。</li>
</ul>

<p>在 <em>O(K)</em> 的情况中，为了使代码并发执行，程序在运行时有一些固定开销，比如消息传递，上下文切换，给共享数据上锁（即使在一个单核的机器上）。但是通过并发总能得到一些伸缩性（尽管很有限）和更快的响应速度。</p>

<p>值得注意的是，<em>O(1)</em> 和 <em>O(K)</em> 都是用“你不能做什么”来描述的。一旦目标硬件有很可变的并行性，操作系统支持并发，而你又可以在程序的 CPU 密集型操作中找到足够多的独立性使它们可以缩放，还是把 <em>O(N)</em> 作为你的为目标吧。</p>

<h3>O(N)：可扩展的吞吐量和免费的午餐</h3>

<p>可扩展吞吐量的关键在于如何表示大量隐藏的并发性，又不以显示编码的方式写在程序中，根据输入（消息数量，数据大小等等）进行缩放，而且在执行的时候有效地映射到一台机器上的 N 个核上（N 可变）。</p>

<p>我们主要可以通过开发自然并行性的方法来发现可扩展的并发：</p>

<ul>
<li>在算法中开发并行性：例如在递归排序算法中，可以它的从分治结构中开发出并行性。</li>
<li>在数据结构中开发并行性：例如在遍历一棵树的时候，可以开发每个节点的子树中开发出独立性。而在编译时源代码的不同层次结构也具有独立性，源代码之间是粗颗粒度的独立性，同一个文件中类和方法之间是较细颗粒度的并行。</li>
</ul>

<p>我们可以把程序（尤其是 CPU 受限任务）拆成一堆“零碎活”——用独立的工作块来表示，这些工作块可大可小，阻塞非阻塞，子结构或是独立的。然后寄希望于运行系统时重新调整应用程序——将这些“碎活”有效地分配给当前用户系统可以得到的一切并行部件。</p>

<p>OpenMP 支持一些受约束的 <em>O(N)</em> 风格，但是它们主要用于整数作索引的数组循环，对 STL、.NET 和 Java 中容器的迭代器效果不佳。而今天表示这些“杂碎活”更多的方法是在一个线程池中对这些“活”现式地调度执行（例如 Java 的 ThreadPoolExecutor 和 .Net 的 BackgroundWorker），我们在上个月的专栏 <a href="#scalability-note-2">[2]</a> 中提到过。不幸的是，这会造成大量的上下文切换开销，因此你最好保证每个“活”的计算量大于“把它交给一个执行线程”所需要的计算。这个限制在未来可能会随着语言和运行时的发展有所减轻。</p>

<p><em>O(N)</em> 是“让免费的午餐回来”和“让所有核都很忙”的关键，它让我们的程序在昨天单核的机器上可以正常运行，在今天四核的机器上可以运行得更快，在明天的 64 核的机器上运行得再快一点……直到我们在程序中耗尽每一个 CPU。对一个线程池驱动的程序来讲，在一个单核机器上，系统让一个工作线程从一片“活”海中把“活”一件件取出然后依次完成；而在一个八核的机器上，系统派出八个线程……以此类推。<a href="#scalability-note-2">[4]</a></p>

<p>和 <em>O(K)</em> 一样，<em>O(N)</em> 的程序在单核机器上执行也会有运行时的开销，除了 <em>O(K)</em> 的那些开销，分治技术还可能有内在的花费（例如规约时不断累加中间结果得到最后的总和），为共享内存加锁的开销也会增加。尽管如此，并发后得到一个好的伸缩性所带来的好处可以让我们无视这些开销。</p>

<p>对于那些希望可以运行在一系列当前和未来的具有不同并行性的硬件上的软件来说，<em>O(N)</em> 是不二的选择——这是目前所有主流桌面、服务器程序的目标。即使你的程序中现在还没有关键的 CPU 受限操作是服从 <em>O(N)</em> 的，不要放弃，试试找一些新的特性是服从 <em>O(N)</em> 的，最起码是 <em>O(K)</em>，你仍有机会开发出在今天的硬件上运行得很好，在今天的硬件上运行得更好，在未来的系统上运行得更更好的软件。</p>

<h3>Notes</h3>

<p>[1] <a id="scalability-note-1"></a>我用了“核”这个词语作为硬件并行测度的一个“代名词”。对于运行在本地机器上的程序来讲，恰当测度通常是“总硬件线程数”，它等于“通道的数量”乘以“每个通道中核的数量”乘以“每个核中线程的数量”；对于分布式程序来讲，这个测度通常是“节点”。</p>

<p>[2] <a id="scalability-note-2"></a> <a href="http://ddj.com/dept/64bit/200001985">The Pillars of Concurrency</a></p>

<p>[3] <a id="scalability-note-3"></a> <a href="http://ddj.com/dept/webservices/184405990">The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software</a></p>

<p>[4] <a id="scalability-note-4"></a> 细节要更复杂些。当一些工作块在等待其它事件时会使相应的工作线程空闲，因此线程池必须创建出更多的工作线程来让系统保持繁忙。</p>

<p>[5] <a id="scalability-note-5"></a> 译注：根据程序的表现，通常可以分为 I/O 受限和 CPU 受限两种，前者频繁使用 I/O 设备，CPU 大部分时间都在等待 I/O 操作的结果；后者需要 CPU 进行大量计算。</p>

<p>[6] <a id="scalability-note-6"></a> 译注：订单（future）一种异步技术，如 Java Future。比如我有一个任务，提交给了 Future，Future 替我完成这个任务。期间我自己可以去做任何想做的事情。一段时间之后，我可以从Future 那儿取出结果。就相当于下了一张订单，一段时间后可以拿着提订单来提货，这期间可以干别的任何事情。</p>



</div>

</body></html>
