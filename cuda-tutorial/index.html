<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>视觉友好的 CUDA 教程</title>


    <script type="text/javascript" src="Tangle/Tangle.js"></script>
    <script type="text/javascript" src="Tangle/TangleKit/mootools.js"></script>
    <script type="text/javascript" src="Tangle/TangleKit/sprintf.js"></script>
    <script type="text/javascript" src="Tangle/TangleKit/BVTouchable.js"></script>
    <script type="text/javascript" src="Tangle/TangleKit/TangleKit.js"></script>
    <script type="text/javascript" src="processing.js"></script>
    <script type="text/javascript" src="tangle.js"></script>
    <script type="text/javascript" src="cudaDraw0.js"></script>    
    <script type="text/javascript" src="cudaDraw1.js"></script>    
    <script type="text/javascript" src="cudaDraw2.js"></script>    
    <script type="text/javascript" src="cudaDraw3.js"></script>    
    <script type="text/javascript" src="cudaDraw4.js"></script>    
    <script type="text/javascript" src="cudaDraw5.js"></script>    


    <link rel="stylesheet" href="Tangle/TangleKit/TangleKit.css" type="text/css">
    <link rel="stylesheet" href="style.css" type="text/css">
</head>

<body onload="setUpTangle();">

  <div class="container">
    <div class="header">
      <h1>视觉友好的 CUDA 教程：矩阵乘法</h1>
    </div>
    <div class="content">
      <div>


      <h2>前言</h2>

      <p>本教程以矩阵乘法为例，演示了如何将 CUDA thread 与数据（也就是矩阵中元素）一一映射的过程。</p>

      <p>假设你已经对 CUDA 编程有了最基础的了解（比如知道什么是 block，什么是 grid），只是在写第一个程序时感到无从下手。</p>

      
      <h2>步骤</h2>

      <p>代码由两部分组成，为了尽量简洁，我们省略了与理解程序无关的代码，仅仅罗列出了代码所需要完成的功能。</p>


      <p>主机端（Host）代码需要完成以下步骤：</p>
      <ul>
        <li>分配主存</li>
        <li>分配显存，初始化 A、B 数组</li>
        <li>数据传输（将 A,B 数组从主存拷贝到显存）</li>
        <li>调用 kernel 函数</li>
        <li>数据传输（将 C 数组从显存拷贝到主存）</li>
      </ul>

      <p>设备端（Device）代码要做这些事情：</p>
      <ul>
        <li>利用 CUDA 提供的内建变量（如 threadIdx）将当前 thread 映射到要操作的数据上</li>
        <li>矩阵 A 的第 row 行与矩阵 B 的第 col 列进行点积操作，结果保存到矩阵 C 的 (row, col) 位置</li>
      </ul>
      

      <h2>显存的分配</h2>
      <p>首先根据矩阵的大小为其分配显存，两个输入矩阵，一个输出矩阵（方便起见，假设矩阵长和宽均为 N）：</p>

      <p>拖动代码中的 N 试试：</p>
      <code id="array1"><pre>
#define N <span data-var="N" class="TKAdjustableNumber" data-min="1" data-max="40" ></span>      

cudaMalloc((void**)&matA_d, sizeof(int)*N*N);          
cudaMalloc((void**)&matB_d, sizeof(int)*N*N);          
cudaMalloc((void**)&matC_d, sizeof(int)*N*N);</pre></code>
      <canvas id="canvas0"></canvas>

      <h2>设计 grid 和 block 的维度</h2>


      <p>假设 N 已定，如何设计 grid 和 block 的维度？（block 和 grid 是 CUDA 编程模型中两个重要的概念，所有 thread 将被组织成 block 块的形式，同一个 block 中的线程可以共享数据、同步；block 又被组织成 grid。）</p>
                                           

      <p>想象你要用下面的绿色小方块（代表 thread）去匹配上面<b>某一个矩阵</b>中的黄色小方块（代表矩阵元素），如何选取 grid 和 block 的维度，可以让 thread 覆盖所有的数据？</p>

      <p>拖动下面的蓝色数字，答案可能不止一种：</p>

      <code id="cuda1"><pre>
dim3 blocksPerGrid(<span data-var="gridDim_x" class="TKAdjustableNumber" data-min="1" data-max="10"></span>, <span data-var="gridDim_y" class="TKAdjustableNumber" data-min="1" data-max="10"></span>);          
dim3 threadsPerBlock(<span data-var="blockDim_x" class="TKAdjustableNumber" data-min="1" data-max="16"></span>, <span data-var="blockDim_y" class="TKAdjustableNumber" data-min="1" data-max="16"></span>);  </pre></code>
      </div>

      <canvas id="canvas1"></canvas>


      


      <p>假设矩阵的宽度为 16，所以我们用 16 个 thread 构成 1 个 block，用 16 个 block 构成一个 grid：</p>
      <code><pre>
dim3 blocksPerGrid(4, 4);
dim3 threadsPerBlock(4, 4);</pre></code>
      <canvas id="canvas3"></canvas>



      <p>当然你也可以这么做，但是我们不提倡：</p>
      <code><pre>
dim3 blocksPerGrid(16, 1);
dim3 threadsPerBlock(1, 16);</pre></code>
      <canvas id="canvas4"></canvas>



      <h2>Kernel 函数</h2>

      <p>怎么利用 CUDA kernel 函数中提供的内建变量（threadIdx 等）将 thread 映射到矩阵中呢？</p>

      <p>我们用以下代码实现：</p>

      

      <code id="cuda2"><pre>
__global__void kernel(int* a, int* b, int* c) {
    int col(<b><span data-var="x"></span></b>) = threadIdx.x(<span data-var="threadIdx_x" class="TKAdjustableNumber" data-min="0" data-max="3"></span>) + blockIdx.x(<span data-var="blockIdx_x" class="TKAdjustableNumber" data-min="0" data-max="3"></span>) * blockDim.x;
    int row(<b><span data-var="y"></span></b>) = threadIdx.y(<span data-var="threadIdx_y" class="TKAdjustableNumber" data-min="0" data-max="3"></span>) + blockIdx.y(<span data-var="blockIdx_y" class="TKAdjustableNumber" data-min="0" data-max="3"></span>) * blockDim.y;
    int sum = 0, i;
    for (i=0; i&lt;N; i(<span data-var="i" class="TKAdjustableNumber" data-min="0" data-max="15"></span>)++) {
        sum += (a[row*N + i] * b[i*N + col]);
    }
    c[row*N + col] = sum;
}</pre></code>


      <p>拖动 threadIdx.x/y（代表每个 block 中 thread 的索引） 和 blockIdx.x/y（代表每个 grid 中 block 的索引），观察：</p>
      

      <ul>
      <li>col 是怎样随着 threadIdx.x 和 blockIdx.x 变化的</li>
      <li>row 是怎样随着 threadIdx.y 和 blockIdx.y 变化的</li>
      </ul>

      <canvas id="canvas2"></canvas>
    <p>提示：你还可以拖动上面 for 循环中的 i ～</p>


    <h2>等等</h2>
    <p>grid 和 block 的维度有上限，假设我们的矩阵很大很大怎么办？</p>


    <p>这时我们可以用有限的 thread 迭代地去覆盖“无限”的矩阵。假设我们的矩阵的维度是 17，而我们定义的 grid 是一个 2*2 的方阵，block 是一个 2*2 的方阵，我们可以在 kernel 中使用两层循环：</p>
    <p>在拖动 blockIdx 和 threadIdx 的同时拖动 m 和 n 的值，观察 thread 和 矩阵元素是如何匹配的：</p>

                                                                                                                                                                             

    <code id="cuda3"><pre>
__global__void kernel(int* a, int* b, int* c) {
    int m, n, i, sum = 0;
    for (m=0; m*(blockDim.x+gridDim.x)&lt;N; m(<span data-var="u" class="TKAdjustableNumber" data-min="0" data-max="4"></span>)++) {         
        for (n=0; n*(blockDim.y+gridDim.y)&lt;N; n(<span data-var="v" class="TKAdjustableNumber" data-min="0" data-max="4"></span>)++) { 
            int col(<b><span data-var="x"></span></b>) = threadIdx.x(<span data-var="threadIdx_x" class="TKAdjustableNumber" data-min="0" data-max="1"></span>) + blockIdx.x(<span data-var="blockIdx_x" class="TKAdjustableNumber" data-min="0" data-max="1"></span>) * blockDim.x + m * gridDim.x * blockDim.x;
            int row(<b><span data-var="y"></span></b>) = threadIdx.y(<span data-var="threadIdx_y" class="TKAdjustableNumber" data-min="0" data-max="1"></span>) + blockIdx.y(<span data-var="blockIdx_y" class="TKAdjustableNumber" data-min="0" data-max="1"></span>) * blockDim.y + n * gridDim.y * blockDim.y;
            for (i=0; i&lt;N; i(<span data-var="i" class="TKAdjustableNumber" data-min="0" data-max="16"></span>)++) {
                sum += (a[row*N + i] * b[i*N + col]);
            }
            c[row*N + col] = sum;
        }
    }
}</pre></code>
    <canvas id="canvas5"></canvas>

    <p>不过一般情况下，不可能出现 thread 数量不够覆盖矩阵元素的情况。</p>

      <h2>再等等</h2>
      <p>为什么 col 和 row 会跑到矩阵外面去？比如当我把 m 、threadIdx.x、blockIdx.x 拖到最右边的时候。</p>
      <p>是的，当如果矩形的维度不是 block 和 grid 维度之积的整数倍时就会发生这种情况，我们要用 thread 覆盖所有的矩阵元素，但是又有一些 thread 是不需要用到的。怎么办？</p>
      <p>我们可以用一句条件语句过滤出那些有效的 thread，即可以映射到矩阵内部的 thread，如下：</p>

      <code><pre>
             int col = ...
             int row = ...
             if (col >= N || row >= N)
                 return;</pre></code>
      <h2>TODO</h2>

  <p>以上这些仅仅是一个雏形，我采用了 <a href="http://worrydream.com/Tangle/">Tangle</a> 和 <a href="http://processingjs.org/">processing.js</a> 实现，你可以做得更多：</p>


  <ul>
    <li>将数据传输的过程可视化</li>
    <li>将 CUDA 中其他一些概念可视化（比如 Stream，线程同步……）</li>
    <li>提供自动分析 CUDA 代码并实现可视化的工具……</li>
    <li>……也就是一个可视化的 CUDA 编程环境</li>
  </ul>
  <p>Email: yichao at email dot ustc dot edu dot cn </p>

  

</div>


    <div class="footer"><p>by onesuper. Oct 17, 2012.</p></div>



  </div>

</body>
</html>
